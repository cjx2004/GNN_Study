{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "\n",
    "class PyG_GATConv(MessagePassing):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(PyG_GATConv, self).__init__(aggr='add')\n",
    "        self.lin = nn.Linear(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_i, x_j, edge_index):\n",
    "        return x_j\n",
    "\n",
    "class PyG_SAGEConv(MessagePassing):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(PyG_SAGEConv, self).__init__(aggr='mean')\n",
    "        self.lin = nn.Linear(in_channel, out_channel)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        return self.propagate(edge_index, x=x)\n",
    "\n",
    "    def message(self, x_j):\n",
    "        return x_j\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "        [2., 2., 2., 2., 2., 2., 2., 2.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n",
      "tensor([[1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1., 1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "edge_index = torch.tensor([[0,1,1,2,2,4],[2,0,2,3,4,3]])\n",
    "x = torch.ones((5, 8))\n",
    "conv = PyG_GATConv(8, 4)\n",
    "output = conv(x, edge_index)\n",
    "print(output)\n",
    "conv = PyG_SAGEConv(8, 4)\n",
    "output = conv(x, edge_index)\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "\n",
    "class DGL_GATConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, num_heads):\n",
    "        super(DGL_GATConv, self).__init__()\n",
    "        self.fc = nn.Linear(in_channel, out_channel * num_heads)\n",
    "        self.attn_fc = nn.Linear(out_channel * 2, 1)  # 修改了这里的输入维度\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = self.fc(h)\n",
    "            g.apply_edges(fn.u_add_v('h', 'h', 'h_sum'))\n",
    "            g.edata['attn'] = F.leaky_relu(self.attn_fc(g.edata['h_sum']))\n",
    "            g.update_all(fn.u_mul_e('h', 'attn', 'm'), fn.sum('m', 'h'))\n",
    "            return g.ndata.pop('h')\n",
    "\n",
    "class DGL_SAGEConv(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel):\n",
    "        super(DGL_SAGEConv, self).__init__()\n",
    "        self.fc = nn.Linear(in_channel * 2, out_channel)\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.update_all(message_func=fn.copy_u('h', 'm'),\n",
    "                         reduce_func=fn.mean('m', 'h_neigh'))\n",
    "            h_src = g.ndata['h']  # original node features\n",
    "            h_dst = h_src[:g.num_dst_nodes()]  # features of the destination nodes\n",
    "            h = torch.cat((h_src, h_dst), dim=1)  # concatenate features\n",
    "            return F.relu(self.fc(h))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1215, -0.0206, -0.1269,  0.0274,  0.0818, -0.0645,  0.0467,  0.0457],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.2430, -0.0412, -0.2538,  0.0548,  0.1635, -0.1290,  0.0935,  0.0915],\n",
      "        [ 0.2430, -0.0412, -0.2538,  0.0548,  0.1635, -0.1290,  0.0935,  0.0915],\n",
      "        [ 0.1215, -0.0206, -0.1269,  0.0274,  0.0818, -0.0645,  0.0467,  0.0457]],\n",
      "       grad_fn=<GSpMMBackward>)\n",
      "tensor([[0.1816, 0.3301, 0.0000, 0.9639],\n",
      "        [0.1816, 0.3301, 0.0000, 0.9639],\n",
      "        [0.1816, 0.3301, 0.0000, 0.9639],\n",
      "        [0.1816, 0.3301, 0.0000, 0.9639],\n",
      "        [0.1816, 0.3301, 0.0000, 0.9639]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "src = torch.tensor([0, 1, 1, 2, 2, 4])\n",
    "dst = torch.tensor([2, 0, 2, 3, 4, 3])\n",
    "h = torch.ones((5, 8))\n",
    "g = dgl.graph((src, dst))\n",
    "conv = DGL_GATConv(8, 4, num_heads=2)  # 增加num_heads=2\n",
    "output = conv(g, h)\n",
    "print(output)\n",
    "conv = DGL_SAGEConv(8, 4)\n",
    "output = conv(g, h)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
