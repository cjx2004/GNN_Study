{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Planetoid\n",
    "dataset = Planetoid(\"./\", \"Cora\", transform=T.NormalizeFeatures())\n",
    "data = dataset[0]\n",
    "\n",
    "x = data.x\n",
    "edge_index = data.edge_index\n",
    "edge_weight = data.edge_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing\n",
    "from torch_geometric.utils import add_self_loops, degree\n",
    "\n",
    "class PyG_GCNConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(PyG_GCNConv, self).__init__(aggr='add') \n",
    "        self.lin = torch.nn.Linear(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        # Step 1: Add self-loops to the adjacency matrix.\n",
    "        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))\n",
    "        # Step 2: Linearly transform node feature matrix.\n",
    "        x = self.lin(x)\n",
    "        # Step 3: Compute normalization.\n",
    "        row, col = edge_index\n",
    "        deg = degree(row, x.size(0), dtype=x.dtype)\n",
    "        deg_inv_sqrt = deg.pow(-0.5)\n",
    "        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]\n",
    "        # Step 4-6: Start propagating messages.\n",
    "        return self.propagate(edge_index, x=x, norm=norm)\n",
    "\n",
    "    def message(self, x_j, norm):    \n",
    "        # Normalize node features.\n",
    "        return norm.view(-1, 1) * x_j\n",
    "\n",
    "    def update(self, aggr_out):        \n",
    "        # Step 5: Return new node embeddings.\n",
    "        return aggr_out\n",
    "\n",
    "class PyG_GCN(nn.Module):\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
    "        super(PyG_GCN, self).__init__()\n",
    "        self.conv1 = PyG_GCNConv(in_channels, hidden_channels)\n",
    "        self.conv2 = PyG_GCNConv(hidden_channels, out_channels)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        \n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return F.log_softmax(x, dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 1, Loss: 1.9619, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 2, Loss: 1.9612, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 3, Loss: 1.9605, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 4, Loss: 1.9597, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 5, Loss: 1.9590, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 6, Loss: 1.9583, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 7, Loss: 1.9576, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 8, Loss: 1.9569, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 9, Loss: 1.9561, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 10, Loss: 1.9554, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 11, Loss: 1.9547, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 12, Loss: 1.9539, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 13, Loss: 1.9532, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 14, Loss: 1.9524, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 15, Loss: 1.9516, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 16, Loss: 1.9508, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 17, Loss: 1.9500, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 18, Loss: 1.9492, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 19, Loss: 1.9484, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 20, Loss: 1.9476, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 21, Loss: 1.9468, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 22, Loss: 1.9459, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 23, Loss: 1.9451, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 24, Loss: 1.9442, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 25, Loss: 1.9433, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 26, Loss: 1.9424, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 27, Loss: 1.9415, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 28, Loss: 1.9405, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 29, Loss: 1.9396, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 30, Loss: 1.9386, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 31, Loss: 1.9377, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 32, Loss: 1.9367, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 33, Loss: 1.9357, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 34, Loss: 1.9347, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 35, Loss: 1.9337, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 36, Loss: 1.9326, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 37, Loss: 1.9316, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 38, Loss: 1.9306, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 39, Loss: 1.9295, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 40, Loss: 1.9284, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 41, Loss: 1.9274, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 42, Loss: 1.9263, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 43, Loss: 1.9252, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 44, Loss: 1.9241, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 45, Loss: 1.9230, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 46, Loss: 1.9219, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 47, Loss: 1.9208, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 48, Loss: 1.9196, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 49, Loss: 1.9185, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 50, Loss: 1.9173, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 51, Loss: 1.9161, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 52, Loss: 1.9149, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 53, Loss: 1.9138, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 54, Loss: 1.9125, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 55, Loss: 1.9113, Train Acc: 0.1429, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 56, Loss: 1.9101, Train Acc: 0.1500, Val Acc: 0.3160, Test Acc: 0.3190\n",
      "INFO:root:Epoch: 57, Loss: 1.9089, Train Acc: 0.1500, Val Acc: 0.3180, Test Acc: 0.3220\n",
      "INFO:root:Epoch: 58, Loss: 1.9076, Train Acc: 0.1500, Val Acc: 0.3180, Test Acc: 0.3220\n",
      "INFO:root:Epoch: 59, Loss: 1.9063, Train Acc: 0.1643, Val Acc: 0.3200, Test Acc: 0.3280\n",
      "INFO:root:Epoch: 60, Loss: 1.9051, Train Acc: 0.1857, Val Acc: 0.3200, Test Acc: 0.3280\n",
      "INFO:root:Epoch: 61, Loss: 1.9038, Train Acc: 0.1857, Val Acc: 0.3200, Test Acc: 0.3280\n",
      "INFO:root:Epoch: 62, Loss: 1.9025, Train Acc: 0.1857, Val Acc: 0.3220, Test Acc: 0.3320\n",
      "INFO:root:Epoch: 63, Loss: 1.9012, Train Acc: 0.1929, Val Acc: 0.3240, Test Acc: 0.3330\n",
      "INFO:root:Epoch: 64, Loss: 1.8999, Train Acc: 0.2071, Val Acc: 0.3320, Test Acc: 0.3400\n",
      "INFO:root:Epoch: 65, Loss: 1.8985, Train Acc: 0.2357, Val Acc: 0.3320, Test Acc: 0.3400\n",
      "INFO:root:Epoch: 66, Loss: 1.8972, Train Acc: 0.2429, Val Acc: 0.3340, Test Acc: 0.3450\n",
      "INFO:root:Epoch: 67, Loss: 1.8959, Train Acc: 0.2500, Val Acc: 0.3380, Test Acc: 0.3510\n",
      "INFO:root:Epoch: 68, Loss: 1.8945, Train Acc: 0.2643, Val Acc: 0.3360, Test Acc: 0.3510\n",
      "INFO:root:Epoch: 69, Loss: 1.8931, Train Acc: 0.2857, Val Acc: 0.3420, Test Acc: 0.3550\n",
      "INFO:root:Epoch: 70, Loss: 1.8918, Train Acc: 0.2857, Val Acc: 0.3440, Test Acc: 0.3570\n",
      "INFO:root:Epoch: 71, Loss: 1.8904, Train Acc: 0.3143, Val Acc: 0.3440, Test Acc: 0.3570\n",
      "INFO:root:Epoch: 72, Loss: 1.8890, Train Acc: 0.3214, Val Acc: 0.3440, Test Acc: 0.3570\n",
      "INFO:root:Epoch: 73, Loss: 1.8875, Train Acc: 0.3286, Val Acc: 0.3480, Test Acc: 0.3660\n",
      "INFO:root:Epoch: 74, Loss: 1.8861, Train Acc: 0.3286, Val Acc: 0.3480, Test Acc: 0.3660\n",
      "INFO:root:Epoch: 75, Loss: 1.8847, Train Acc: 0.3571, Val Acc: 0.3560, Test Acc: 0.3720\n",
      "INFO:root:Epoch: 76, Loss: 1.8832, Train Acc: 0.3714, Val Acc: 0.3540, Test Acc: 0.3720\n",
      "INFO:root:Epoch: 77, Loss: 1.8818, Train Acc: 0.3857, Val Acc: 0.3580, Test Acc: 0.3760\n",
      "INFO:root:Epoch: 78, Loss: 1.8803, Train Acc: 0.3857, Val Acc: 0.3580, Test Acc: 0.3760\n",
      "INFO:root:Epoch: 79, Loss: 1.8788, Train Acc: 0.4071, Val Acc: 0.3600, Test Acc: 0.3860\n",
      "INFO:root:Epoch: 80, Loss: 1.8773, Train Acc: 0.4071, Val Acc: 0.3620, Test Acc: 0.3890\n",
      "INFO:root:Epoch: 81, Loss: 1.8758, Train Acc: 0.4071, Val Acc: 0.3700, Test Acc: 0.3950\n",
      "INFO:root:Epoch: 82, Loss: 1.8743, Train Acc: 0.4286, Val Acc: 0.3840, Test Acc: 0.4010\n",
      "INFO:root:Epoch: 83, Loss: 1.8728, Train Acc: 0.4500, Val Acc: 0.3920, Test Acc: 0.4090\n",
      "INFO:root:Epoch: 84, Loss: 1.8712, Train Acc: 0.4643, Val Acc: 0.3980, Test Acc: 0.4120\n",
      "INFO:root:Epoch: 85, Loss: 1.8697, Train Acc: 0.4929, Val Acc: 0.4020, Test Acc: 0.4170\n",
      "INFO:root:Epoch: 86, Loss: 1.8681, Train Acc: 0.5143, Val Acc: 0.4080, Test Acc: 0.4230\n",
      "INFO:root:Epoch: 87, Loss: 1.8665, Train Acc: 0.5286, Val Acc: 0.4120, Test Acc: 0.4320\n",
      "INFO:root:Epoch: 88, Loss: 1.8649, Train Acc: 0.5500, Val Acc: 0.4200, Test Acc: 0.4440\n",
      "INFO:root:Epoch: 89, Loss: 1.8633, Train Acc: 0.5786, Val Acc: 0.4260, Test Acc: 0.4480\n",
      "INFO:root:Epoch: 90, Loss: 1.8617, Train Acc: 0.6071, Val Acc: 0.4340, Test Acc: 0.4620\n",
      "INFO:root:Epoch: 91, Loss: 1.8601, Train Acc: 0.6714, Val Acc: 0.4380, Test Acc: 0.4700\n",
      "INFO:root:Epoch: 92, Loss: 1.8584, Train Acc: 0.6857, Val Acc: 0.4480, Test Acc: 0.4700\n",
      "INFO:root:Epoch: 93, Loss: 1.8568, Train Acc: 0.6857, Val Acc: 0.4500, Test Acc: 0.4840\n",
      "INFO:root:Epoch: 94, Loss: 1.8551, Train Acc: 0.7143, Val Acc: 0.4660, Test Acc: 0.4940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Epoch: 95, Loss: 1.8534, Train Acc: 0.7214, Val Acc: 0.4740, Test Acc: 0.5070\n",
      "INFO:root:Epoch: 96, Loss: 1.8518, Train Acc: 0.7214, Val Acc: 0.4880, Test Acc: 0.5220\n",
      "INFO:root:Epoch: 97, Loss: 1.8501, Train Acc: 0.7214, Val Acc: 0.4940, Test Acc: 0.5260\n",
      "INFO:root:Epoch: 98, Loss: 1.8483, Train Acc: 0.7286, Val Acc: 0.4980, Test Acc: 0.5350\n",
      "INFO:root:Epoch: 99, Loss: 1.8466, Train Acc: 0.7643, Val Acc: 0.4960, Test Acc: 0.5350\n",
      "INFO:root:Epoch: 100, Loss: 1.8449, Train Acc: 0.7571, Val Acc: 0.5000, Test Acc: 0.5490\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "\n",
    "# Set up logging configuration\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "# Build your training pipeline\n",
    "hidden_dim = 16\n",
    "lr = 0.001\n",
    "epochs = 100\n",
    "model = PyG_GCN(dataset.num_features, hidden_dim, dataset.num_classes)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr, weight_decay=5e-4)\n",
    "\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(out[data.train_mask], data.y[data.train_mask])  # Use negative log likelihood loss\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test():\n",
    "    model.eval()\n",
    "    pred = model(data.x, data.edge_index).argmax(dim=-1)\n",
    "\n",
    "    accs = []\n",
    "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
    "        accs.append(int((pred[mask] == data.y[mask]).sum()) / int(mask.sum()))\n",
    "    return accs\n",
    "\n",
    "best_val_acc = 0\n",
    "for epoch in range(1, epochs + 1):\n",
    "    loss = train()\n",
    "    train_acc, val_acc, tmp_test_acc = test()\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        test_acc = tmp_test_acc\n",
    "    logging.info(\"Epoch: %d, Loss: %.4f, Train Acc: %.4f, Val Acc: %.4f, Test Acc: %.4f\", epoch, loss, train_acc, val_acc, test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading C:\\Users\\31293\\.dgl\\cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\31293\\.dgl\\cora_v2.zip: 100%|███████████████████████████████████████████████| 132k/132k [00:00<00:00, 796kB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file to C:\\Users\\31293\\.dgl\\cora_v2_d697a464\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "Training...\n",
      "Epoch 0, Loss: 1.945562720298767, Validation Accuracy: 0.3300\n",
      "Epoch 20, Loss: 1.5899418592453003, Validation Accuracy: 0.6940\n",
      "Epoch 40, Loss: 0.9424986839294434, Validation Accuracy: 0.7400\n",
      "Epoch 60, Loss: 0.41126778721809387, Validation Accuracy: 0.7520\n",
      "Epoch 80, Loss: 0.17714110016822815, Validation Accuracy: 0.7640\n",
      "Epoch 100, Loss: 0.0898863673210144, Validation Accuracy: 0.7660\n",
      "Epoch 120, Loss: 0.05379465967416763, Validation Accuracy: 0.7720\n",
      "Epoch 140, Loss: 0.03615487366914749, Validation Accuracy: 0.7720\n",
      "Epoch 160, Loss: 0.026218481361865997, Validation Accuracy: 0.7720\n",
      "Epoch 180, Loss: 0.0200169887393713, Validation Accuracy: 0.7740\n",
      "Testing...\n",
      "Test accuracy 0.7790\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "\n",
    "import dgl\n",
    "import dgl.nn as dglnn\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl import AddSelfLoop\n",
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "transform = (\n",
    "        AddSelfLoop()\n",
    "    )\n",
    "data = CoraGraphDataset(transform=transform)\n",
    "g = data[0]\n",
    "features = g.ndata[\"feat\"]\n",
    "labels = g.ndata[\"label\"]\n",
    "masks = g.ndata[\"train_mask\"], g.ndata[\"val_mask\"], g.ndata[\"test_mask\"]\n",
    "\n",
    "class DGL_GCNConv(nn.Module):\n",
    "    def __init__(self, in_feats, out_feats):\n",
    "        super(DGL_GCNConv, self).__init__()\n",
    "        self.conv = dglnn.GraphConv(in_feats, out_feats)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        return self.conv(g, features)\n",
    "\n",
    "class DGL_GCN(nn.Module):\n",
    "    def __init__(self, in_feats, hidden_size, num_classes):\n",
    "        super(DGL_GCN, self).__init__()\n",
    "        self.conv1 = DGL_GCNConv(in_feats, hidden_size)\n",
    "        self.conv2 = DGL_GCNConv(hidden_size, num_classes)\n",
    "    \n",
    "    def forward(self, g, features):\n",
    "        x = F.relu(self.conv1(g, features))\n",
    "        x = self.conv2(g, x)\n",
    "        return x\n",
    "\n",
    "def train(g, features, labels, masks, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    train_mask, val_mask, test_mask = masks\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(200):\n",
    "        model.train()\n",
    "        logits = model(g, features)\n",
    "        loss = loss_fn(logits[train_mask], labels[train_mask])\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 20 == 0:\n",
    "            val_acc = evaluate(g, features, labels, val_mask, model)\n",
    "            print(f\"Epoch {epoch}, Loss: {loss.item()}, Validation Accuracy: {val_acc:.4f}\")\n",
    "\n",
    "def evaluate(g, features, labels, mask, model):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        logits = model(g, features)\n",
    "        logits = logits[mask]\n",
    "        labels = labels[mask]\n",
    "        _, indices = torch.max(logits, dim=1)\n",
    "        correct = torch.sum(indices == labels)\n",
    "        return correct.item() * 1.0 / len(labels)\n",
    "\n",
    "model = DGL_GCN(features.shape[1], 16, data.num_classes)\n",
    "print(\"Training...\")\n",
    "train(g, features, labels, masks, model)\n",
    "\n",
    "# test the model\n",
    "print(\"Testing...\")\n",
    "acc = evaluate(g, features, labels, masks[2], model)\n",
    "print(\"Test accuracy {:.4f}\".format(acc))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
