{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train_data = MNIST(\n",
    "    root = \"data\",\n",
    "    download = True,\n",
    "    train = True,\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "test_data = MNIST(\n",
    "    root = \"data\",\n",
    "    download = True,\n",
    "    train = False,\n",
    "    transform = torchvision.transforms.ToTensor()\n",
    "    )\n",
    "\n",
    "train_dataloader = DataLoader(train_data, batch_size = 64)\n",
    "test_dataloader = DataLoader(test_data, batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 7 * 7)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Batch 0, Loss: 2.3093\n",
      "Epoch 0, Batch 100, Loss: 0.2486\n",
      "Epoch 0, Batch 200, Loss: 0.1532\n",
      "Epoch 0, Batch 300, Loss: 0.1863\n",
      "Epoch 0, Batch 400, Loss: 0.0582\n",
      "Epoch 0, Batch 500, Loss: 0.1159\n",
      "Epoch 0, Batch 600, Loss: 0.1285\n",
      "Epoch 0, Batch 700, Loss: 0.1108\n",
      "Epoch 0, Batch 800, Loss: 0.2194\n",
      "Epoch 0, Batch 900, Loss: 0.0855\n",
      "Epoch 0, Average Loss: 0.1828\n",
      "Epoch 1, Batch 0, Loss: 0.0906\n",
      "Epoch 1, Batch 100, Loss: 0.1365\n",
      "Epoch 1, Batch 200, Loss: 0.0224\n",
      "Epoch 1, Batch 300, Loss: 0.0856\n",
      "Epoch 1, Batch 400, Loss: 0.0167\n",
      "Epoch 1, Batch 500, Loss: 0.1098\n",
      "Epoch 1, Batch 600, Loss: 0.0701\n",
      "Epoch 1, Batch 700, Loss: 0.0424\n",
      "Epoch 1, Batch 800, Loss: 0.1447\n",
      "Epoch 1, Batch 900, Loss: 0.0260\n",
      "Epoch 1, Average Loss: 0.0502\n",
      "Epoch 2, Batch 0, Loss: 0.0315\n",
      "Epoch 2, Batch 100, Loss: 0.0914\n",
      "Epoch 2, Batch 200, Loss: 0.0178\n",
      "Epoch 2, Batch 300, Loss: 0.0853\n",
      "Epoch 2, Batch 400, Loss: 0.0147\n",
      "Epoch 2, Batch 500, Loss: 0.0645\n",
      "Epoch 2, Batch 600, Loss: 0.0425\n",
      "Epoch 2, Batch 700, Loss: 0.0255\n",
      "Epoch 2, Batch 800, Loss: 0.1605\n",
      "Epoch 2, Batch 900, Loss: 0.0102\n",
      "Epoch 2, Average Loss: 0.0328\n",
      "Epoch 3, Batch 0, Loss: 0.0270\n",
      "Epoch 3, Batch 100, Loss: 0.0422\n",
      "Epoch 3, Batch 200, Loss: 0.0133\n",
      "Epoch 3, Batch 300, Loss: 0.0514\n",
      "Epoch 3, Batch 400, Loss: 0.0161\n",
      "Epoch 3, Batch 500, Loss: 0.0259\n",
      "Epoch 3, Batch 600, Loss: 0.0292\n",
      "Epoch 3, Batch 700, Loss: 0.0109\n",
      "Epoch 3, Batch 800, Loss: 0.2085\n",
      "Epoch 3, Batch 900, Loss: 0.0098\n",
      "Epoch 3, Average Loss: 0.0237\n",
      "Epoch 4, Batch 0, Loss: 0.0080\n",
      "Epoch 4, Batch 100, Loss: 0.0314\n",
      "Epoch 4, Batch 200, Loss: 0.0231\n",
      "Epoch 4, Batch 300, Loss: 0.0587\n",
      "Epoch 4, Batch 400, Loss: 0.0229\n",
      "Epoch 4, Batch 500, Loss: 0.0056\n",
      "Epoch 4, Batch 600, Loss: 0.0896\n",
      "Epoch 4, Batch 700, Loss: 0.0049\n",
      "Epoch 4, Batch 800, Loss: 0.0834\n",
      "Epoch 4, Batch 900, Loss: 0.0084\n",
      "Epoch 4, Average Loss: 0.0167\n",
      "Epoch 5, Batch 0, Loss: 0.0142\n",
      "Epoch 5, Batch 100, Loss: 0.0043\n",
      "Epoch 5, Batch 200, Loss: 0.0088\n",
      "Epoch 5, Batch 300, Loss: 0.0013\n",
      "Epoch 5, Batch 400, Loss: 0.0150\n",
      "Epoch 5, Batch 500, Loss: 0.0086\n",
      "Epoch 5, Batch 600, Loss: 0.0277\n",
      "Epoch 5, Batch 700, Loss: 0.0128\n",
      "Epoch 5, Batch 800, Loss: 0.0780\n",
      "Epoch 5, Batch 900, Loss: 0.0130\n",
      "Epoch 5, Average Loss: 0.0136\n",
      "Epoch 6, Batch 0, Loss: 0.0040\n",
      "Epoch 6, Batch 100, Loss: 0.0014\n",
      "Epoch 6, Batch 200, Loss: 0.0201\n",
      "Epoch 6, Batch 300, Loss: 0.0018\n",
      "Epoch 6, Batch 400, Loss: 0.0078\n",
      "Epoch 6, Batch 500, Loss: 0.0082\n",
      "Epoch 6, Batch 600, Loss: 0.0049\n",
      "Epoch 6, Batch 700, Loss: 0.0025\n",
      "Epoch 6, Batch 800, Loss: 0.1308\n",
      "Epoch 6, Batch 900, Loss: 0.0025\n",
      "Epoch 6, Average Loss: 0.0122\n",
      "Epoch 7, Batch 0, Loss: 0.0089\n",
      "Epoch 7, Batch 100, Loss: 0.0016\n",
      "Epoch 7, Batch 200, Loss: 0.0188\n",
      "Epoch 7, Batch 300, Loss: 0.0686\n",
      "Epoch 7, Batch 400, Loss: 0.0222\n",
      "Epoch 7, Batch 500, Loss: 0.0120\n",
      "Epoch 7, Batch 600, Loss: 0.0218\n",
      "Epoch 7, Batch 700, Loss: 0.0005\n",
      "Epoch 7, Batch 800, Loss: 0.0383\n",
      "Epoch 7, Batch 900, Loss: 0.0088\n",
      "Epoch 7, Average Loss: 0.0093\n",
      "Epoch 8, Batch 0, Loss: 0.0101\n",
      "Epoch 8, Batch 100, Loss: 0.0012\n",
      "Epoch 8, Batch 200, Loss: 0.0048\n",
      "Epoch 8, Batch 300, Loss: 0.0529\n",
      "Epoch 8, Batch 400, Loss: 0.0056\n",
      "Epoch 8, Batch 500, Loss: 0.0007\n",
      "Epoch 8, Batch 600, Loss: 0.0001\n",
      "Epoch 8, Batch 700, Loss: 0.0012\n",
      "Epoch 8, Batch 800, Loss: 0.0090\n",
      "Epoch 8, Batch 900, Loss: 0.0051\n",
      "Epoch 8, Average Loss: 0.0087\n",
      "Epoch 9, Batch 0, Loss: 0.0024\n",
      "Epoch 9, Batch 100, Loss: 0.0022\n",
      "Epoch 9, Batch 200, Loss: 0.0019\n",
      "Epoch 9, Batch 300, Loss: 0.0001\n",
      "Epoch 9, Batch 400, Loss: 0.0072\n",
      "Epoch 9, Batch 500, Loss: 0.0015\n",
      "Epoch 9, Batch 600, Loss: 0.0010\n",
      "Epoch 9, Batch 700, Loss: 0.0007\n",
      "Epoch 9, Batch 800, Loss: 0.0768\n",
      "Epoch 9, Batch 900, Loss: 0.0019\n",
      "Epoch 9, Average Loss: 0.0076\n"
     ]
    }
   ],
   "source": [
    "model = CNNModel()  \n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "epochs = 10  \n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()  # 将模型设置为训练模式\n",
    "    total_loss = 0\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(train_dataloader):\n",
    "        optimizer.zero_grad()  # 清零梯度\n",
    "        \n",
    "        output = model(data)  # 前向传播\n",
    "        loss = loss_func(output, target)  # 计算损失\n",
    "        loss.backward()  # 反向传播\n",
    "        optimizer.step()  # 更新参数\n",
    "        \n",
    "        total_loss += loss.item()  # 累积总损失\n",
    "        \n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Epoch {}, Batch {}, Loss: {:.4f}'.format(epoch, batch_idx, loss.item()))\n",
    "    \n",
    "    print('Epoch {}, Average Loss: {:.4f}'.format(epoch, total_loss / len(train_dataloader)))\n",
    "\n",
    "# 可选地，在训练后在测试数据集上评估模型\n",
    "model.eval()  # 将模型设置为评估模式\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in test_dataloader:\n",
    "        output = model(data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
